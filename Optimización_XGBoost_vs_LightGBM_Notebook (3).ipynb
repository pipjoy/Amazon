{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "654b428f",
   "metadata": {},
   "source": [
    "# Predicción de Ventas de Productos con Modelos de Machine Learning\n",
    "\n",
    "Este proyecto busca predecir la cantidad de ventas aproximadas de productos de Amazon, utilizando características como precio, descuento, calificación y categoría.\n",
    "\n",
    "Los modelos utilizados son **XGBoost** y **LightGBM**, optimizados con **RandomizedSearchCV** para encontrar la mejor combinación de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f046fde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Cargar el dataset desde Kaggle\n",
    "df = kagglehub.load_dataset(KaggleDatasetAdapter.PANDAS, \"karkavelrajaj/amazon-sales-dataset\", \"amazon.csv\")\n",
    "\n",
    "# Mostrar información básica\n",
    "print(\"Dataset cargado correctamente\")\n",
    "print(\"Dimensiones:\", df.shape)\n",
    "print(\"Tipos de datos:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Vista previa\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d0a80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Limpiar columnas numéricas\n",
    "df['discounted_price_num'] = df['discounted_price'].replace({'[₹,]': ''}, regex=True).astype(float)\n",
    "df['actual_price_num'] = df['actual_price'].replace({'[₹,]': ''}, regex=True).astype(float)\n",
    "df['discount_percentage_num'] = df['discount_percentage'].str.replace('%', '', regex=False).astype(float)\n",
    "df['rating_num'] = pd.to_numeric(df['rating'], errors='coerce')\n",
    "df['rating_count_num'] = df['rating_count'].replace({',': ''}, regex=True).astype(float)\n",
    "\n",
    "# Eliminar filas con NaN en las columnas clave\n",
    "df.dropna(subset=['rating_num', 'rating_count_num'], inplace=True)\n",
    "\n",
    "# Mostrar las primeras filas tras la limpieza\n",
    "df[['discounted_price_num', 'actual_price_num', 'discount_percentage_num', 'rating_num', 'rating_count_num']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94ae3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extraer la categoría principal\n",
    "df['main_category'] = df['category'].str.split('|').str[0]\n",
    "\n",
    "# Ver las categorías principales únicas\n",
    "print(\"Categorías principales únicas:\", df['main_category'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988e6b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Histograma de ventas (rating_count_num)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(df['rating_count_num'], bins=50, color='skyblue', edgecolor='black')\n",
    "plt.yscale('log')\n",
    "plt.title('Distribución de las ventas (Rating Count)', fontsize=14)\n",
    "plt.xlabel('Número de valoraciones (ventas)', fontsize=12)\n",
    "plt.ylabel('Frecuencia (escala logarítmica)', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Correlación entre las principales variables\n",
    "corr = df[['discounted_price_num', 'actual_price_num', 'discount_percentage_num', 'rating_num', 'rating_count_num']].corr()\n",
    "\n",
    "# Mostrar la matriz de correlación\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(corr, cmap='coolwarm', interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "plt.title('Matriz de Correlación de Variables', fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6517caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Selección de las características a usar\n",
    "X = df[['discounted_price_num', 'discount_percentage_num', 'rating_num', 'main_category']].copy()\n",
    "\n",
    "# One-hot encoding para la categoría\n",
    "X = pd.get_dummies(X, columns=['main_category'], drop_first=True)\n",
    "\n",
    "# Variable objetivo (rating_count_num)\n",
    "y = df['rating_count_num']\n",
    "\n",
    "# Ver las primeras filas para verificar la codificación\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21541349",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Definir el modelo XGBoost\n",
    "model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Realizar validación cruzada con 5 pliegues\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "# Mostrar el RMSE promedio\n",
    "mean_rmse = -cv_scores.mean()\n",
    "print(\"RMSE promedio de XGBoost con validación cruzada de 5 pliegues:\", mean_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97119021",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Espacio de búsqueda para RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.6, 0.7, 0.8],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8],\n",
    "    'gamma': [0, 1],\n",
    "    'alpha': [0, 0.1],\n",
    "    'lambda': [0, 0.1]\n",
    "}\n",
    "\n",
    "# Crear el modelo XGBoost\n",
    "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Realizar búsqueda aleatoria con 100 combinaciones\n",
    "random_search = RandomizedSearchCV(xgb_model, param_distributions=param_dist, n_iter=100, cv=3, scoring='neg_root_mean_squared_error', random_state=42, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Ajustar el modelo\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# Mostrar los mejores parámetros encontrados\n",
    "print(\"Mejores hiperparámetros encontrados:\", random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df45e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reentrenar el modelo XGBoost con los mejores parámetros\n",
    "best_xgb = random_search.best_estimator_\n",
    "best_xgb.fit(X, y)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred = best_xgb.predict(X)\n",
    "\n",
    "# Calcular las métricas de evaluación\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R²:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec50bee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Crear el modelo LightGBM\n",
    "lgb_model = lgb.LGBMRegressor(num_leaves=31, learning_rate=0.05, n_estimators=100)\n",
    "\n",
    "# Entrenamiento del modelo LightGBM\n",
    "lgb_model.fit(X, y)\n",
    "\n",
    "# Realizar predicciones con el modelo LightGBM\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "# Calcular las métricas de evaluación para LightGBM\n",
    "mae_lgb = mean_absolute_error(y_test, y_pred_lgb)\n",
    "rmse_lgb = np.sqrt(mean_squared_error(y_test, y_pred_lgb))\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "\n",
    "# Mostrar las métricas para LightGBM\n",
    "print(\"LightGBM -> MAE:\", mae_lgb, \"RMSE:\", rmse_lgb, \"R²:\", r2_lgb)\n",
    "\n",
    "# Comparación con el modelo XGBoost\n",
    "# Entrenar el modelo XGBoost (como ya lo tenemos entrenado)\n",
    "y_pred_xgb = best_xgb.predict(X_test)\n",
    "\n",
    "# Calcular las métricas de evaluación para XGBoost\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "# Mostrar las métricas para XGBoost\n",
    "print(\"XGBoost -> MAE:\", mae_xgb, \"RMSE:\", rmse_xgb, \"R²:\", r2_xgb)\n",
    "\n",
    "# Comparación de resultados\n",
    "print(\"\n",
    "Comparación de Modelos:\")\n",
    "print(f\"LightGBM vs XGBoost: \n",
    "MAE: {mae_lgb} vs {mae_xgb} \n",
    "RMSE: {rmse_lgb} vs {rmse_xgb} \n",
    "R²: {r2_lgb} vs {r2_xgb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d9bb9f",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusiones\n",
    "\n",
    "- **XGBoost optimizado** con **RandomizedSearchCV** mostró el mejor rendimiento en términos de **RMSE** y **R²**.\n",
    "- **LightGBM** también tiene un buen rendimiento, pero XGBoost superó a LightGBM en **RMSE** y **R²**.\n",
    "- Las características más importantes para predecir las ventas fueron **precio con descuento** y **calificación**.\n",
    "- Las recomendaciones para mejorar el rendimiento incluyen ajustar los **porcentajes de descuento** y mejorar las **calificaciones** de los productos.\n",
    "\n",
    "## Recomendaciones para el Negocio\n",
    "\n",
    "1. **Mejorar la calificación de los productos**.\n",
    "2. **Aplicar descuentos estratégicos** en productos que necesitan un empujón en ventas.\n",
    "3. **Optimizar las categorías de productos** para identificar las más rentables.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
